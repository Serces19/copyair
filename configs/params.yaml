# CopyAir - Image-to-Image Translation Configuration

# Parámetros de entrada/salida
data:
  input_dir: "data/03_processed/input"
  gt_dir: "data/03_processed/gt"
  frames_dir: "data/01_raw/input"
  output_dir: "output_inference"
  models_dir: "models"

# Parámetros del modelo
model:
  # Arquitecturas disponibles:
  # - unet: U-Net clásica
  # - nafnet: NAFNet HD (mejor para pocas imágenes)
  # - convnext: ConvNeXt U-Net (excelente para few-shot)
  # - mambair: MambaIRv2 (SOTA, global context, eficiente)
  
  architecture: "unet"  # Cambiar a "nafnet", "convnext" o "mambair"
  
  # Para NAFNet, ConvNeXt y MambaIR, especificar tamaño:
  size: "base"  # nano, tiny, small, base, large (según arquitectura)
  
  # Parámetros generales
  in_channels: 3
  out_channels: 3
  base_channels: 64  # Solo para UNet
  activation: "mish"  # Solo para UNet: relu, gelu, mish, silu, leaky_relu
  
  # Para ConvNeXt: drop_path_rate (regularización)
  drop_path_rate: 0.01  # 0.05-0.2 recomendado para pocas imágenes
  
  # Opciones avanzadas de arquitectura (UNet, ConvNeXt, NAFNet)
  use_batchnorm: false    # Solo UNet
  use_dropout: false     # UNet y NAFNet
  dropout_p: 0.00         # Probabilidad de dropout
  use_transpose: false   # UNet y ConvNeXt (False = Upsample + Conv)

# Parámetros de entrenamiento
training:
  epochs: 2500
  batch_size: 8  # UNet puede manejar batch_size más grande
  learning_rate: 1e-3 # Reducido para estabilidad (antes 1e-3 o 2e-4) 
  weight_decay: 1e-4
  
  # Memory Optimization
  mixed_precision: true  # Automatic Mixed Precision (50% menos VRAM, 2-3x más rápido)
  gradient_accumulation_steps: 1  # Acumular gradientes (1 = desactivado, 2+ = simula batch más grande)
  clear_cache_every_n_epochs: 10  # Limpiar cache CUDA cada N épocas (evita fragmentación)
  
  # Optimizador
  optimizer:
    type: "adamw" # adam, adamw, sgd, rmsprop
    beta1: 0.9
    beta2: 0.999
    momentum: 0.9 # Solo para SGD
  
  # Learning Rate Scheduler
  scheduler:
    type: "cosine"
    params:
      T_max: 5000 # Número total de épocas
      eta_min: 1e-8 # LR mínimo al final
 
  
  # Validación
  # Si es 0, se entrena con TODO el dataset y se valida con 1 muestra aleatoria (sin augs) por época
  val_split: 0
  val_interval: 25  # Validar cada N épocas (para eficiencia en few-shot)
  viz_interval: 250
  
  # Checkpoint
  save_interval: 500
  early_stopping_patience: 600

# Parámetros de pérdida
loss:
  lambda_l1: 0.0
  lambda_ssim: 0.2
  lambda_perceptual: 0.8
  lambda_laplacian: 0.0
  lambda_ffl: 0.00      # Focal Frequency Loss (Detalle fino)
  lambda_dreamsim: 0.00 # DreamSim Loss (Coherencia semántica)
  lambda_charbonnier: 0.0 # Charbonnier Loss (Robust L1) - Recomendado: 1.0 (si reemplaza L1)
  lambda_sobel: 0.0       # Sobel Loss (Bordes) - Recomendado: 0.1-0.2
  lambda_multiscale: 0.3  # [NEW] Supervisión Estructural (Pyramid Loss)


# Masked Loss (Entrenamiento Ponderado)
masked_loss:
  enabled: false
  threshold: 0.05      # Diferencia mínima para considerar "cambio"
  dilation_kernel: 5   # Engrosar máscara (píxeles)
  blur_kernel: 5       # Suavizar bordes (píxeles)

# Aumentación de datos
augmentation:
  enabled: true
  img_size: 256
  horizontal_flip_p: 0.0
  vertical_flip_p: 0.0
  rotation_limit: 0
  gaussian_noise_p: 0.0
  gaussian_blur_p: 0.1
  color_jitter_p: 0.1

# Hardware
device: "cuda"  # cuda o cpu
num_workers: 4
pin_memory: true

# Logging y experimentos
logging:
  level: "INFO"
  log_dir: "logs"
  
mlflow:
  enabled: true
  experiment_name: "copyair_experiments"
  tracking_uri: "mlruns" # Local directory or server URI

# Inferencia en video
inference:
  target_fps: 24
  frame_sample_rate: 1  # Procesar cada N frames
