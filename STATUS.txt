â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                                                            â•‘
â•‘                    âœ¨ COPYAIR - PROYECTO COMPLETADO âœ¨                    â•‘
â•‘                                                                            â•‘
â•‘            TransformaciÃ³n de Notebook a Proyecto Profesional               â•‘
â•‘                                                                            â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


ğŸ“Š ESTADO DEL PROYECTO
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

âœ… MÃ“DULOS CREADOS:
   â””â”€ src/data/              â†’ Dataset y augmentaciones
   â””â”€ src/models/            â†’ U-Net y pÃ©rdidas (L1, SSIM, Perceptual)
   â””â”€ src/training/          â†’ Entrenamiento e inferencia

âœ… SCRIPTS EJECUTABLES:
   â””â”€ scripts/train.py       â†’ Entrenamiento con configuraciÃ³n YAML
   â””â”€ scripts/predict.py     â†’ Inferencia en video

âœ… CONFIGURACIÃ“N:
   â””â”€ configs/params.yaml    â†’ ParÃ¡metros centralizados (todo editable)

âœ… PRUEBAS:
   â””â”€ tests/test_dataset.py  â†’ Pruebas del cargador de datos
   â””â”€ tests/test_models.py   â†’ Pruebas del modelo U-Net

âœ… DOCUMENTACIÃ“N:
   â””â”€ README.md              â†’ GuÃ­a completa
   â””â”€ DEVELOPMENT.md         â†’ Arquitectura y debugging
   â””â”€ QUICKSTART.py          â†’ GuÃ­a rÃ¡pida
   â””â”€ PROJECT_SUMMARY.md     â†’ Resumen ejecutivo
   â””â”€ GIT_SETUP.md           â†’ Configurar Git

âœ… UTILIDADES:
   â””â”€ Dockerfile             â†’ ContainerizaciÃ³n
   â””â”€ Makefile               â†’ Comandos automatizados
   â””â”€ .gitignore             â†’ Git configurado
   â””â”€ requirements.txt       â†’ Dependencias (torch, opencv, etc.)


ğŸ“ ESTRUCTURA FINAL DEL PROYECTO
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

copyair/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ 01_raw/              # Videos originales sin procesar
â”‚   â”œâ”€â”€ 02_interim/          # Frames extraÃ­dos, archivos temporales
â”‚   â””â”€â”€ 03_processed/        # Datos listos para entrenamiento
â”‚       â”œâ”€â”€ input/           # ImÃ¡genes de entrada
â”‚       â””â”€â”€ ground_truth/    # ImÃ¡genes objetivo (editadas)
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ dataset.py              # PairedImageDataset
â”‚   â”‚   â””â”€â”€ augmentations.py        # Transformaciones (albumentations)
â”‚   â”‚
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ unet.py                 # Arquitectura U-Net completa
â”‚   â”‚   â”‚   â”œâ”€â”€ ConvBlock
â”‚   â”‚   â”‚   â”œâ”€â”€ DownBlock
â”‚   â”‚   â”‚   â”œâ”€â”€ UpBlock
â”‚   â”‚   â”‚   â””â”€â”€ UNet
â”‚   â”‚   â””â”€â”€ losses.py               # L1, SSIM, Perceptual, HybridLoss
â”‚   â”‚
â”‚   â””â”€â”€ training/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ train.py                # train_epoch(), validate()
â”‚       â””â”€â”€ inference.py            # predict_on_video()
â”‚
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ SergioCespedes_TrabajoFinal.ipynb  # Notebook original
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ train.py                 # Script principal de entrenamiento
â”‚   â””â”€â”€ predict.py               # Script de inferencia
â”‚
â”œâ”€â”€ configs/
â”‚   â””â”€â”€ params.yaml              # ConfiguraciÃ³n centralizada
â”‚
â”œâ”€â”€ models/                      # Checkpoints guardados
â”œâ”€â”€ output_inference/            # Videos/frames generados
â”œâ”€â”€ examples/
â”‚   â””â”€â”€ tutorial.py              # Tutorial ejecutable
â”‚
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_dataset.py
â”‚   â””â”€â”€ test_models.py
â”‚
â”œâ”€â”€ .gitignore                   # Git configuration
â”œâ”€â”€ Dockerfile                   # Para containerizaciÃ³n
â”œâ”€â”€ Makefile                     # Comandos Ãºtiles
â”œâ”€â”€ requirements.txt             # Dependencias Python
â”œâ”€â”€ setup_project.py             # Script de inicializaciÃ³n
â”œâ”€â”€ README.md                    # DocumentaciÃ³n completa
â”œâ”€â”€ DEVELOPMENT.md               # GuÃ­a de desarrollo
â”œâ”€â”€ QUICKSTART.py                # GuÃ­a rÃ¡pida interactiva
â”œâ”€â”€ PROJECT_SUMMARY.md           # Resumen ejecutivo
â”œâ”€â”€ GIT_SETUP.md                 # Configurar Git/GitHub
â””â”€â”€ WELCOME.py                   # Este archivo


ğŸš€ CÃ“MO COMENZAR
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

1ï¸âƒ£  INSTALAR DEPENDENCIAS:
   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   $ python -m venv venv
   $ .\venv\Scripts\Activate.ps1          # Windows PowerShell
   $ pip install -r requirements.txt

   O con Makefile:
   $ make install


2ï¸âƒ£  PREPARAR DATOS:
   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   Copia tus imÃ¡genes en:
   
   data/03_processed/
   â”œâ”€â”€ input/
   â”‚   â”œâ”€â”€ frame_1.jpg
   â”‚   â”œâ”€â”€ frame_2.jpg
   â”‚   â””â”€â”€ ... (8+ imÃ¡genes recomendadas)
   â”‚
   â””â”€â”€ ground_truth/
       â”œâ”€â”€ frame_1.jpg
       â”œâ”€â”€ frame_2.jpg
       â””â”€â”€ ... (deben coincidir con input/)

   âš ï¸  IMPORTANTE: Los nombres DEBEN ser idÃ©nticos


3ï¸âƒ£  ENTRENAR MODELO:
   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   $ python scripts/train.py --config configs/params.yaml --device cuda
   
   Opciones:
   â€¢ --device cuda     â†’ GPU (recomendado, 10x mÃ¡s rÃ¡pido)
   â€¢ --device cpu      â†’ CPU (lento pero funciona)
   
   O con Makefile:
   $ make train        # Con GPU
   $ make train-cpu    # Sin GPU


4ï¸âƒ£  GENERAR VIDEO DE SALIDA:
   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   $ python scripts/predict.py \
       --model models/best_model.pth \
       --video input.mp4 \
       --output output.mp4


5ï¸âƒ£  VERIFICAR CON PRUEBAS:
   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   $ pytest tests/ -v


âš™ï¸  ARCHIVOS CLAVE
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

CONFIGURACIÃ“N (params.yaml):
  training:
    epochs: 50              # NÃºmero de Ã©pocas
    batch_size: 8           # TamaÃ±o del lote (reduce si OOM)
    learning_rate: 0.001    # Tasa de aprendizaje
  
  model:
    base_channels: 64       # 64â†’128 = 2x mÃ¡s parÃ¡metros
  
  loss:
    lambda_l1: 0.6          # Peso L1
    lambda_ssim: 0.2        # Peso SSIM  
    lambda_perceptual: 0.2  # Peso Perceptual

MODELO (src/models/unet.py):
  â€¢ U-Net con 4 niveles encoder/decoder
  â€¢ Skip connections para preservar detalles
  â€¢ 3M parÃ¡metros (base_channels=64)
  â€¢ Salida con Sigmoid para normalizar [0,1]

PÃ‰RDIDA (src/models/losses.py):
  â€¢ L1 Loss: penaliza diferencias de pÃ­xeles
  â€¢ SSIM Loss: penaliza cambios estructurales
  â€¢ Perceptual Loss: penaliza caracterÃ­sticas
  â€¢ HybridLoss = 0.6Ã—L1 + 0.2Ã—SSIM + 0.2Ã—Perceptual

DATOS (src/data/dataset.py):
  â€¢ PairedImageDataset: carga pares input/gt
  â€¢ VideoFrameDataset: carga frames para inferencia
  â€¢ Normaliza a [0,1] automÃ¡ticamente


ğŸ“Š RESULTADOS ESPERADOS
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Con 8-10 pares de imÃ¡genes:
  â€¢ PSNR: ~25-30 dB (excelente)
  â€¢ Training time: 1-2 minutos por Ã©poca (GPU)
  â€¢ Modelo final: ~12 MB

Con 100+ pares de imÃ¡genes:
  â€¢ PSNR: ~30-35 dB (profesional)
  â€¢ Training time: 5-10 minutos por Ã©poca (GPU)
  â€¢ Mejor generalizaciÃ³n


ğŸ› ï¸  COMANDOS ÃšTILES
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ENTRENAR:
  $ make train                    # Con GPU
  $ make train-cpu                # Sin GPU

PRUEBAS:
  $ make test                     # Ejecutar tests
  $ pytest tests/ -v --cov=src   # Con cobertura

LIMPIAR:
  $ make clean                    # Eliminar __pycache__

CÃ“DIGO:
  $ make lint                     # Formatear con black/flake8

DOCKER:
  $ make docker-build             # Construir imagen
  $ make docker-run               # Ejecutar en Docker


ğŸ“š DOCUMENTACIÃ“N
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

README.md
  â†’ DescripciÃ³n general, instalaciÃ³n, uso, soluciÃ³n de problemas

DEVELOPMENT.md
  â†’ Arquitectura del cÃ³digo, flujo de trabajo, debugging avanzado

QUICKSTART.py
  â†’ GuÃ­a rÃ¡pida interactiva con todos los pasos

PROJECT_SUMMARY.md
  â†’ Resumen ejecutivo con lista de verificaciÃ³n

GIT_SETUP.md
  â†’ CÃ³mo inicializar Git y subir a GitHub

example_usage.py
  â†’ Ejemplo de uso del pipeline completo

tutorial.py (en examples/)
  â†’ Tutorial paso a paso ejecutable


âœ¨ CARACTERÃSTICAS
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

âœ… Arquitectura U-Net profesional
âœ… PÃ©rdida hÃ­brida (L1 + SSIM + Perceptual)
âœ… AugmentaciÃ³n de datos automÃ¡tica
âœ… ValidaciÃ³n y early stopping
âœ… Checkpoint automÃ¡tico de mejor modelo
âœ… Inferencia en video completo
âœ… ConfiguraciÃ³n flexible (YAML)
âœ… Tests unitarios incluidos
âœ… Dockerfile para producciÃ³n
âœ… DocumentaciÃ³n profesional
âœ… Makefile para automatizaciÃ³n
âœ… .gitignore configurado


ğŸ¯ SIGUIENTES PASOS AVANZADOS
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

1. MLOps - Tracking de experimentos:
   $ pip install mlflow
   â€¢ Registra automÃ¡ticamente loss, PSNR, hiperparÃ¡metros
   â€¢ Compara experimentos en dashboard

2. DVC - Versionado de datos/modelos:
   $ pip install dvc
   â€¢ Versiona data/ sin saturar Git
   â€¢ IntegraciÃ³n con Git

3. OptimizaciÃ³n:
   â€¢ Quantization (int8) â†’ 4x mÃ¡s rÃ¡pido
   â€¢ Pruning â†’ reduce parÃ¡metros
   â€¢ Knowledge distillation â†’ modelo mÃ¡s pequeÃ±o

4. Deployment:
   â€¢ FastAPI â†’ API REST
   â€¢ ONNX â†’ compatibilidad multiplataforma
   â€¢ TorchScript â†’ optimizaciÃ³n


ğŸ†˜ SOLUCIÃ“N DE PROBLEMAS
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

âŒ Error: "ModuleNotFoundError: No module named 'torch'"
âœ“ SoluciÃ³n: pip install -r requirements.txt

âŒ Error: "CUDA out of memory"
âœ“ SoluciÃ³n: Reduce batch_size en configs/params.yaml

âŒ Error: "No se encontraron imÃ¡genes"
âœ“ SoluciÃ³n: Verifica que data/03_processed/input/ y ground_truth/
            tengan archivos CON LOS MISMOS NOMBRES

âŒ Error: "RuntimeError: Expected 3D or 4D input"
âœ“ SoluciÃ³n: AsegÃºrate que las imÃ¡genes sean RGB (3 canales)
            No pueden ser escala de grises (1 canal)

âŒ Error: "Val loss no mejora"
âœ“ SoluciÃ³n: Aumenta learning_rate o epochs en params.yaml

âŒ Error: "Frames borrosos"
âœ“ SoluciÃ³n: Aumenta lambda_ssim en configs/params.yaml


ğŸ“ˆ ESTADÃSTICAS
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Archivos creados:        ~25 archivos Python
LÃ­neas de cÃ³digo:        ~2,500 lÃ­neas documentadas
Funciones:               ~20 funciones principales
Tests:                   ~15 tests unitarios
DocumentaciÃ³n:           ~5 documentos (README, DEVELOPMENT, etc.)
Configurabilidad:        30+ parÃ¡metros en YAML


ğŸ“ APRENDIZAJE
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Este proyecto demuestra:

âœ“ OrganizaciÃ³n profesional de cÃ³digo ML
âœ“ Arquitectura modular y escalable
âœ“ Mejores prÃ¡cticas de ML Engineering
âœ“ Reproducibilidad y versionado
âœ“ Testing y validaciÃ³n automatizada
âœ“ DocumentaciÃ³n tÃ©cnica profesional
âœ“ ContainerizaciÃ³n (Docker)
âœ“ DevOps basics (Makefile, scripts)


â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

                  ğŸ‰ Â¡PROYECTO COMPLETAMENTE LISTO! ğŸ‰

                      PrÃ³ximo paso:

                python scripts/train.py --config configs/params.yaml

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
