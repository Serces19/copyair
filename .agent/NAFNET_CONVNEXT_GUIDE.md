# NAFNet y ConvNeXt - Gu√≠a de Uso

## Resumen

Se han implementado **NAFNet HD** y **ConvNeXt** optimizados para **few-shot learning** con pocas im√°genes (5-15) de alta resoluci√≥n variable.

## Arquitecturas Implementadas

### 1. **NAFNet HD** (Nonlinear Activation Free Network)
**Paper**: "Simple Baselines for Image Restoration" (ECCV 2022)

**Caracter√≠sticas:**
- ‚úÖ Sin activaciones no lineales tradicionales (ReLU, GELU)
- ‚úÖ SimpleGate: activaci√≥n eficiente basada en multiplicaci√≥n
- ‚úÖ Simplified Channel Attention (SCA)
- ‚úÖ **Muy eficiente computacionalmente** (8.4% del costo de SOTA)
- ‚úÖ **Excelente para pocas im√°genes**
- ‚úÖ Maneja alta resoluci√≥n nativamente

**Tama√±os disponibles:**
| Tama√±o | Par√°metros | Recomendado para | Dropout |
|--------|-----------|------------------|---------|
| `small` | ~15M | 5-8 im√°genes | 0.10 |
| `base` | ~28M | 8-12 im√°genes | 0.05 |
| `large` | ~45M | >12 im√°genes | 0.00 |

---

### 2. **ConvNeXt U-Net**
**Paper**: "A ConvNet for the 2020s" (CVPR 2022)

**Caracter√≠sticas:**
- ‚úÖ CNN moderna inspirada en Vision Transformers
- ‚úÖ Depthwise convolutions grandes (7x7)
- ‚úÖ LayerNorm + GELU
- ‚úÖ Inverted bottleneck design
- ‚úÖ **Excelente para few-shot learning**
- ‚úÖ **Escalable a alta resoluci√≥n**

**Tama√±os disponibles:**
| Tama√±o | Par√°metros | Recomendado para | Drop Path |
|--------|-----------|------------------|-----------|
| `nano` | ~15M | 5-8 im√°genes | 0.05 |
| `tiny` | ~28M | 8-12 im√°genes | 0.10 |
| `small` | ~50M | 10-15 im√°genes | 0.15 |
| `base` | ~89M | >15 im√°genes | 0.20 |

---

## Configuraci√≥n en params.yaml

### NAFNet Small (5-8 im√°genes)
```yaml
model:
  architecture: "nafnet"
  size: "small"
  in_channels: 3
  out_channels: 3
```

### NAFNet Base (8-12 im√°genes) - **RECOMENDADO**
```yaml
model:
  architecture: "nafnet"
  size: "base"
  in_channels: 3
  out_channels: 3
```

### ConvNeXt Nano (5-8 im√°genes)
```yaml
model:
  architecture: "convnext"
  size: "nano"
  in_channels: 3
  out_channels: 3
  drop_path_rate: 0.05  # Regularizaci√≥n
```

### ConvNeXt Tiny (8-12 im√°genes) - **RECOMENDADO**
```yaml
model:
  architecture: "convnext"
  size: "tiny"
  in_channels: 3
  out_channels: 3
  drop_path_rate: 0.10
```

---

## Comparaci√≥n: NAFNet vs ConvNeXt vs U-Net

| Caracter√≠stica | NAFNet | ConvNeXt | U-Net |
|---------------|--------|----------|-------|
| **Par√°metros** | 15-45M | 15-89M | 30M |
| **Velocidad** | ‚ö°‚ö°‚ö° Muy r√°pida | ‚ö°‚ö° R√°pida | ‚ö°‚ö°‚ö° Muy r√°pida |
| **Memoria** | üíæ Baja | üíæüíæ Media | üíæ Baja |
| **Few-shot** | ‚≠ê‚≠ê‚≠ê Excelente | ‚≠ê‚≠ê‚≠ê Excelente | ‚≠ê‚≠ê Buena |
| **Alta Resoluci√≥n** | ‚≠ê‚≠ê‚≠ê Excelente | ‚≠ê‚≠ê‚≠ê Excelente | ‚≠ê‚≠ê Buena |
| **Calidad** | ‚≠ê‚≠ê‚≠ê SOTA | ‚≠ê‚≠ê‚≠ê SOTA | ‚≠ê‚≠ê Buena |
| **Overfitting** | ‚≠ê‚≠ê‚≠ê Resistente | ‚≠ê‚≠ê‚≠ê Resistente | ‚≠ê Propenso |

---

## Recomendaciones por Caso de Uso

### üì∏ 5-8 Im√°genes de Alta Resoluci√≥n
**Opci√≥n 1 (M√°s r√°pida):**
```yaml
model:
  architecture: "nafnet"
  size: "small"
```

**Opci√≥n 2 (Mejor calidad):**
```yaml
model:
  architecture: "convnext"
  size: "nano"
  drop_path_rate: 0.10
```

**Training:**
```yaml
training:
  epochs: 1000  # M√°s √©pocas para pocas im√°genes
  batch_size: 4  # Batch peque√±o
  learning_rate: 5e-4  # LR bajo
  scheduler:
    type: "cosine"
    params:
      T_max: 1000
      eta_min: 1e-6
```

---

### üì∏ 8-12 Im√°genes de Alta Resoluci√≥n (TU CASO)
**Opci√≥n 1 (Recomendada - Balance):**
```yaml
model:
  architecture: "nafnet"
  size: "base"
```

**Opci√≥n 2 (Mejor para detalles finos):**
```yaml
model:
  architecture: "convnext"
  size: "tiny"
  drop_path_rate: 0.10
```

**Training:**
```yaml
training:
  epochs: 800
  batch_size: 6
  learning_rate: 1e-3
  scheduler:
    type: "cosine"
    params:
      T_max: 800
      eta_min: 1e-6
```

---

### üì∏ 12-15 Im√°genes de Alta Resoluci√≥n
**Opci√≥n 1:**
```yaml
model:
  architecture: "nafnet"
  size: "base"
```

**Opci√≥n 2:**
```yaml
model:
  architecture: "convnext"
  size: "small"
  drop_path_rate: 0.15
```

**Training:**
```yaml
training:
  epochs: 600
  batch_size: 8
  learning_rate: 1e-3
  scheduler:
    type: "plateau"
    params:
      patience: 20
      factor: 0.5
```

---

## Ventajas Espec√≠ficas

### NAFNet HD
1. **Eficiencia extrema**: 8.4% del costo computacional de m√©todos SOTA
2. **Sin activaciones no lineales**: Menos par√°metros, m√°s r√°pido
3. **SimpleGate**: Activaci√≥n aprendible sin overhead
4. **Mejor para pocas im√°genes**: Menos propenso a overfitting
5. **Alta resoluci√≥n nativa**: No necesita resize agresivo

### ConvNeXt U-Net
1. **Arquitectura moderna**: Incorpora mejores pr√°cticas de ViTs
2. **Depthwise 7x7**: Captura contexto amplio
3. **Inverted bottleneck**: Mejor flujo de informaci√≥n
4. **Drop Path**: Regularizaci√≥n efectiva para few-shot
5. **Escalabilidad**: F√°cil ajustar tama√±o seg√∫n datos

---

## T√©cnicas de Regularizaci√≥n para Few-Shot

### 1. **Dropout / DropPath**
```yaml
model:
  architecture: "convnext"
  drop_path_rate: 0.10  # 0.05-0.20 seg√∫n cantidad de im√°genes
```

### 2. **Data Augmentation Agresiva**
```yaml
augmentation:
  enabled: true
  horizontal_flip_p: 0.5
  vertical_flip_p: 0.5
  rotation_limit: 30  # M√°s rotaci√≥n
  # Agregar m√°s augmentations
```

### 3. **Learning Rate Bajo**
```yaml
training:
  learning_rate: 5e-4  # M√°s bajo que usual
  weight_decay: 1e-4
```

### 4. **M√°s √âpocas**
```yaml
training:
  epochs: 1000  # 2-3x m√°s que con muchas im√°genes
```

### 5. **Early Stopping Paciente**
```yaml
training:
  early_stopping_patience: 500  # Muy paciente
```

---

## Entrenamiento

```bash
# Editar configs/params.yaml con la configuraci√≥n deseada

# Entrenar
python scripts/train.py --config configs/params.yaml

# Inferencia
python scripts/predict.py --model models/best_model.pth --video input.mp4 --output output.mp4 --native-resolution
```

---

## Monitoreo con MLflow

Ambas arquitecturas loggean autom√°ticamente:
- **Par√°metros del modelo**: arquitectura, size, drop_path_rate
- **M√©tricas**: train_loss, val_loss, PSNR
- **Learning rate**: train/lr
- **Im√°genes de validaci√≥n**: cada 100 √©pocas

```bash
mlflow ui
# Abrir http://localhost:5000
```

---

## Troubleshooting

### Problema: Out of Memory (OOM)
**Soluci√≥n:**
1. Reducir `batch_size`
2. Usar tama√±o m√°s peque√±o (`nano` o `small`)
3. Reducir `img_size` en augmentations
4. Usar `--native-resolution` solo si es necesario

### Problema: Overfitting r√°pido
**Soluci√≥n:**
1. Aumentar `drop_path_rate` (0.15-0.20)
2. M√°s data augmentation
3. Reducir tama√±o del modelo
4. LR m√°s bajo
5. M√°s weight decay

### Problema: Underfitting
**Soluci√≥n:**
1. Modelo m√°s grande (`base` o `large`)
2. M√°s √©pocas
3. LR m√°s alto
4. Menos regularizaci√≥n

---

## Benchmarks Esperados

### NAFNet Base (8-12 im√°genes)
- **PSNR**: 35-40 dB (despu√©s de 500 √©pocas)
- **Tiempo/√©poca**: ~2-3 min (GPU RTX 3090, 256x256)
- **Memoria**: ~4-6 GB VRAM

### ConvNeXt Tiny (8-12 im√°genes)
- **PSNR**: 36-41 dB (despu√©s de 500 √©pocas)
- **Tiempo/√©poca**: ~3-4 min (GPU RTX 3090, 256x256)
- **Memoria**: ~6-8 GB VRAM

---

## Referencias

- **NAFNet**: [Simple Baselines for Image Restoration (ECCV 2022)](https://arxiv.org/abs/2204.04676)
- **ConvNeXt**: [A ConvNet for the 2020s (CVPR 2022)](https://arxiv.org/abs/2201.03545)
- **Few-Shot Learning**: [ConvNeXt-ECA for Few-Shot Classification](https://ieeexplore.ieee.org/document/10222084)

---

## Pr√≥ximos Pasos

1. ‚úÖ Implementar NAFNet y ConvNeXt
2. ‚úÖ Configurar para few-shot learning
3. ‚è≥ Entrenar con tus 5-15 im√°genes
4. ‚è≥ Comparar resultados entre arquitecturas
5. ‚è≥ Fine-tuning de hiperpar√°metros
6. ‚è≥ Evaluar en video de alta resoluci√≥n
